{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendação de filmes a partir de um perfil de usuário\n",
    "\n",
    "\n",
    "Notebook com o intuito de prova de conceito e teste de viabilidade, para a implementação de sistema de recomendações baseados no perfil do usuário.\n",
    "Há duas formas comumente usadas para implementação desse tipo de sistema de recomendações. A primeira é basear a recomendação a partir do que usuários \"similares\" assistiram, similares nesse caso sendo calculados a partir das avaliações dos filmes já assistidos. A outra forma é basear a recomendação a partir simplesmente das próprias avaliações do usuário. Para esse primeiro sprint, optou-se por usar a segunda forma, uma vez que a primeira tem muito risco de ter um desempenho ruim devido aos usuários mudarem preferências, bem como ter muitos usuários para conseguir ter similaridades boas o suficiente.\n",
    "\n",
    "\n",
    "**Dataset**: [\"The Movies Dataset\"](https://www.kaggle.com/rounakbanik/the-movies-dataset), disponível no Kaggle em 18/09/2020\n",
    "\n",
    "**Atenção:** Para execução desse notebook, é necessário download externo dos arquivos do dataset, que não estão disponíveis no repositório do MovieRec. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando e entendo os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a implementação, nós precisaremos dos dados contidos na tabela ratings retirados do TMDb(avaliações) apenas.\n",
    "O ratings, como mostrado logo abaixo, basicamente se consiste no id do usuário que fez a avaliação, o id do filme que ele avaliou, seguido da avaliação em si, que vai de 1 a 5. Outra coluna originalmente colocada na tabela é o timestamp, mas foi retirado pelo não necessidade do uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   userId  movieId  rating\n0       1       31     2.5\n1       1     1029     3.0\n2       1     1061     3.0\n3       1     1129     2.0\n4       1     1172     4.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>31</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1029</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1061</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1129</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1172</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "dfRatings = pd.read_csv(\"ratings_small.csv\", usecols=[\"userId\", \"movieId\", \"rating\"])\n",
    "dfRatingsFull = pd.read_csv(\"ratings.csv\", usecols=[\"userId\", \"movieId\", \"rating\"])\n",
    "dfRatings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "671 users\n9066 movies\n100004 ratings\nFor full dataset\n270896 users\n45115 movies\n26024289 ratings\n"
    }
   ],
   "source": [
    "nUsers = dfRatings.userId.unique().shape[0]\n",
    "nMovies = dfRatings.movieId.unique().shape[0]\n",
    "nUsersFull = dfRatingsFull.userId.unique().shape[0]\n",
    "nMoviesFull = dfRatingsFull.movieId.unique().shape[0]\n",
    "print(str(nUsers) + \" users\")\n",
    "print(str(nMovies) + \" movies\")\n",
    "print(str(dfRatings.shape[0]) + \" ratings\")\n",
    "print(\"For full dataset\")\n",
    "print(str(nUsersFull) + \" users\")\n",
    "print(str(nMoviesFull) + \" movies\")\n",
    "print(str(dfRatingsFull.shape[0]) + \" ratings\")"
   ]
  },
  {
   "source": [
    "# Pré processamento dos dados"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Como comumente temos dados esparsos de avaliações, ou seja, cada usuário avalia muito poucos filmes no total, obviamente, usaremos um classificador Factorization Machines para treinar, uma vez que se comportam muito bem com tais estruturas de dados"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Usaremos One-hot encoding nas tabelas userId e movieId, pois esses classificadores recebem como entrada tais estruturas"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   rating  userId_1  userId_2  userId_3  userId_4  userId_5  userId_6  \\\n0     2.5         1         0         0         0         0         0   \n1     3.0         1         0         0         0         0         0   \n2     3.0         1         0         0         0         0         0   \n3     2.0         1         0         0         0         0         0   \n4     4.0         1         0         0         0         0         0   \n\n   userId_7  userId_8  userId_9  ...  movieId_161084  movieId_161155  \\\n0         0         0         0  ...               0               0   \n1         0         0         0  ...               0               0   \n2         0         0         0  ...               0               0   \n3         0         0         0  ...               0               0   \n4         0         0         0  ...               0               0   \n\n   movieId_161594  movieId_161830  movieId_161918  movieId_161944  \\\n0               0               0               0               0   \n1               0               0               0               0   \n2               0               0               0               0   \n3               0               0               0               0   \n4               0               0               0               0   \n\n   movieId_162376  movieId_162542  movieId_162672  movieId_163949  \n0               0               0               0               0  \n1               0               0               0               0  \n2               0               0               0               0  \n3               0               0               0               0  \n4               0               0               0               0  \n\n[5 rows x 9738 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rating</th>\n      <th>userId_1</th>\n      <th>userId_2</th>\n      <th>userId_3</th>\n      <th>userId_4</th>\n      <th>userId_5</th>\n      <th>userId_6</th>\n      <th>userId_7</th>\n      <th>userId_8</th>\n      <th>userId_9</th>\n      <th>...</th>\n      <th>movieId_161084</th>\n      <th>movieId_161155</th>\n      <th>movieId_161594</th>\n      <th>movieId_161830</th>\n      <th>movieId_161918</th>\n      <th>movieId_161944</th>\n      <th>movieId_162376</th>\n      <th>movieId_162542</th>\n      <th>movieId_162672</th>\n      <th>movieId_163949</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 9738 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "ratingsOneHot = pd.get_dummies(dfRatings, columns=['userId', 'movieId'], sparse=True)\n",
    "ratingsOneHot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No nosso modelo, o rating é o y, que queremos prever, e o restante das colunas é o X\n",
    "y = ratingsOneHot['rating']\n",
    "X = ratingsOneHot[ratingsOneHot.columns.difference(['rating'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0         2.5\n1         3.0\n2         3.0\n3         2.0\n4         4.0\n         ... \n99999     2.5\n100000    4.0\n100001    4.0\n100002    2.5\n100003    3.5\nName: rating, Length: 100004, dtype: float64\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0         25.0\n1         30.0\n2         30.0\n3         20.0\n4         40.0\n          ... \n99999     25.0\n100000    40.0\n100001    40.0\n100002    25.0\n100003    35.0\nName: rating, Length: 100004, dtype: float64"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "print(y) # É preciso converter pra inteiro\n",
    "y = y*10 # como é sabido que as notas só variam na primeira casa decimal, é só multiplicar por 10.\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gasta muito menos tempo e ocupa menos espaço.\n",
    "from scipy.sparse import lil_matrix\n",
    "def data_frame_to_scipy_sparse_matrix(df):\n",
    "    arr = lil_matrix(df.shape, dtype=np.float32)\n",
    "    for i, col in enumerate(df.columns):\n",
    "        ix = df[col] != 0\n",
    "        arr[np.where(ix), i] = 1\n",
    "\n",
    "    return arr.tocsr()\n",
    "\n",
    "X_csr = data_frame_to_scipy_sparse_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train-test split: 0.02 secs\n"
    }
   ],
   "source": [
    "# Dividindo o treinamento e teste.\n",
    "start = time.time()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_csr, y, test_size=0.3, random_state=42)\n",
    "end = time.time()\n",
    "duration = round(end-start, 2)\n",
    "print(\"Train-test split: \" + str(duration) + \" secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training: 105.6 secs\n"
    }
   ],
   "source": [
    "# Treinando o modelo com o algorítmo de regressão logistica.\n",
    "start = time.time()\n",
    "model = LogisticRegressionCV(cv=5, random_state=0, multi_class='ovr', solver = 'liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "duration = round(end-start, 2)\n",
    "print(\"Training: \" + str(duration) + \" secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.33634424371708554"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "y_score = model.predict(X_test)\n",
    "precision_score(y_test, y_score, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.28461435904273047"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=10)\n",
    "neigh.fit(X_train, y_train)\n",
    "y_score = neigh.predict(X_test)\n",
    "precision_score(y_test, y_score, average=\"micro\")"
   ]
  },
  {
   "source": [
    "Resultado não tão bom, e sendo possível o uso do small_ratings apenas"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Usando o pacote Surprise para o Sistema de Recomendação"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estamos usando o SVD pois se comporta melhor quando se trata de matrizes esparsas como é o caso.\n",
    "from surprise import SVD\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader()\n",
    "ratingsDataSet = Dataset.load_from_df(dfRatings, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training: 288.28seconds\n0.8944429156721772\n{'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.2}\n0.6914073692822493\n{'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.2}\n"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"n_epochs\": [5, 10, 20],\n",
    "    \"lr_all\": [0.002, 0.005],\n",
    "    \"reg_all\": [0.2, 0.4, 0.6]\n",
    "}\n",
    "# Estamos utilizando o GridSearchCV para testar vários parâmetros e escolher o melhor\n",
    "ratingsGridSearch = GridSearchCV(SVD, param_grid, measures=[\"rmse\", \"mae\"], cv=5)\n",
    "start = time.time()\n",
    "ratingsGridSearch.fit(ratingsDataSet)\n",
    "end = time.time()\n",
    "duration = round(end-start, 2)\n",
    "print(\"Training: \" + str(duration) + \"seconds\")\n",
    "print(ratingsGridSearch.best_score[\"rmse\"])\n",
    "print(ratingsGridSearch.best_params[\"rmse\"])\n",
    "print(ratingsGridSearch.best_score[\"mae\"])\n",
    "print(ratingsGridSearch.best_params[\"mae\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model data fitting time: 0.0seconds\n"
    }
   ],
   "source": [
    "#Carregar o dataset completo quebra em máquina \"comum\"\n",
    "#ratingsDataSetFull = Dataset.load_from_df(dfRatingsFull, reader)\n",
    "#trainset = ratingsDataSetFull.build_full_trainset()\n",
    "#Treinando novamente a rede com os parametros escolhidos\n",
    "trainset = ratingsDataSet.build_full_trainset()\n",
    "svd = ratingsGridSearch.best_estimator['rmse']\n",
    "start = time.time()\n",
    "svd.fit(trainset)\n",
    "end = time.time()\n",
    "duration = round(end-start, 2)\n",
    "print(\"Model data fitting time: \" + str(duration) + \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Prediction(uid=1, iid=31, r_ui=None, est=2.505569785838023, details={'was_impossible': False})"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "svd.predict(1, 31)"
   ]
  },
  {
   "source": [
    "# Verificando precisão e recall"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.6315894369706037\n0.24221603968048677\n0.616219572776951\n0.23329857056098496\n0.6098507462686578\n0.22873910237827846\n0.5937655240933938\n0.22038391137767907\n0.6223631840796032\n0.24226779856218258\n"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "    return precisions, recalls\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "algo = SVD()\n",
    "\n",
    "for trainset, testset in kf.split(ratingsDataSet):\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=5, threshold=4)\n",
    "\n",
    "    # Precision and recall can then be averaged over all users\n",
    "    print(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "    print(sum(rec for rec in recalls.values()) / len(recalls))"
   ]
  },
  {
   "source": [
    "# Fontes usadas\n",
    "\n",
    "https://www.kaggle.com/rounakbanik/the-movies-dataset?select=ratings.csv\n",
    "\n",
    "https://scikit-learn.org/stable\n",
    "\n",
    "https://www.kaggle.com/ibtesama/getting-started-with-a-movie-recommendation-system\n",
    "\n",
    "https://surprise.readthedocs.io/en/stable/index.html\n",
    "\n",
    "https://github.com/NicolasHug/Surprise\n",
    "\n",
    "https://realpython.com/build-recommendation-engine-collaborative-filtering/\n",
    "\n",
    "https://towardsdatascience.com/various-implementations-of-collaborative-filtering-100385c6dfe0\n",
    "\n",
    "https://www.ethanrosenthal.com/2015/11/02/intro-to-collaborative-filtering/\n",
    "\n",
    "https://docs.scipy.org/doc/\n",
    "\n",
    "https://towardsdatascience.com/beginners-guide-to-creating-an-svd-recommender-system-1fd7326d1f65\n",
    "\n",
    "https://antoinevastel.com/machine%20learning/python/2016/02/14/svd-recommender-system.html\n",
    "\n",
    "https://towardsdatascience.com/recommender-systems-in-practice-cef9033bb23a\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2018/01/factorization-machines/\n",
    "\n",
    "https://towardsdatascience.com/working-with-sparse-data-sets-in-pandas-and-sklearn-d26c1cfbe067"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python_defaultSpec_1600578927543"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}